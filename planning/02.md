
## 1. What the drift model must capture

First, recall from your Key Focus Areas that the drift model should somehow reflect:

* Physical mechanisms: thermal effects, aging, calibration changes
* Stochastic behavior: i.e. randomness, uncertainty, unpredictability
* Time evolution: drift accumulates (or evolves) over time

So the model is not just “drift = constant bias” — it must be *time-varying* and probabilistic.

You will combine a **deterministic part** (if any) and a **stochastic part** for the drift. The stochastic part is often modeled as some random process (random walk, AR, GP, etc.).

---

## 2. Candidate stochastic drift models

Here are a few candidate formulations. Each has different complexity, flexibility, and assumptions.

### 2.1. Simple Random Walk / Brownian Bias Model

This is often the baseline model for drift. In discrete time (sampled at intervals):

$[
d_{k+1} = d_k + w_k, \quad w_k \sim \mathcal{N}(0, \sigma_w^2)
]$

* Here (d_k) is the drift bias at time (k).
* The drift increments (w_k) are zero-mean Gaussian, independent (white noise).
* This is equivalent to modeling drift as **integrated white noise** (i.e. a discrete-time random walk).

**Pros:**

* Very simple, easy to implement
* Good first approximation when drift is slowly accumulating
* Can be embedded directly into a linear Kalman filter

**Cons / Assumptions:**

* No tendency to revert (i.e. drift can wander arbitrarily)
* Assumes drift increments are uncorrelated and Gaussian
* Doesn’t capture smoothness beyond one-step correlation

This is a standard choice in inertial sensor error models (e.g. gyroscope bias drift via random walk) ([VectorNav][1]).

If you like, you can also add a drift “velocity” state so the drift can accelerate:

$d_{k+1} = d_k + v_k \Delta t 
\v_{k+1} = v_k + u_k, \quad u_k \sim \mathcal{N}(0, \sigma_u^2)$

This is a **second-order random walk** (drift with “acceleration” noise).

---

### 2.2. Autoregressive (AR(1)) / Gauss–Markov model for drift

A more structured model is:

$d_{k+1} = \phi , d_k + w_k, \quad | \phi | < 1$

This is a **Gauss–Markov** (i.e. AR(1)) model for drift. It introduces a memory/decay parameter (\phi).

* If $(\phi = 1)$, it reduces to the random walk.
* If $(\phi < 1)$, drift tends to “pull back” (a mean-reversion tendency) or at least not diverge too wildly.

This is common when you assume drift has some persistence but not unbounded accumulation. It is still linear and fits nicely into standard estimation frameworks.

In the continuous-time limit, this corresponds to an **Ornstein–Uhlenbeck** process (a mean-reverting Gaussian process) ([Wikipedia][2]).

---

### 2.3. Drift as a Gaussian Process (GP)

A more flexible, nonparametric way is to model drift (d(t)) as a **Gaussian process** in time:

$d(t) \sim \mathcal{GP} \bigl( \mu(t),, K(t, t') \bigr)$

* $(\mu(t))$: mean function (often set to 0 or some drift trend)
* $(K(t, t'))$: covariance (kernel) function, which encodes smoothness, correlation across time, characteristic time scale, etc.

This formulation gives you a **distribution over functions** for drift (i.e. many possible drift trajectories consistent with data). The GP assumption implies every finite vector ([d(t_1), \dots, d(t_n)]) is jointly Gaussian. ([Wikipedia][3])

You will then condition on observed sensor data (or residuals) to infer the posterior distribution of drift and its uncertainty.

Some more advanced works convert GP drift models into an **equivalent state-space form** so you can use Kalman filtering / smoothing, combining the flexibility of GP with computational tractability ([users.aalto.fi][4]).

**Pros:**

* Very flexible — can capture irregular, smooth, or varying drift
* Gives uncertainty estimates (variance) in drift predictions
* Kernel choice allows encoding domain knowledge (e.g. periodic drift, smoothness scale)

**Cons / Challenges:**

* More complex, more hyperparameters (kernel length scale, variance)
* Computational cost for large data (GP naive scaling is (O(n^3)))
* Requires careful kernel design for good performance
* May not be strictly “real-time” unless approximations (sparse GP, state-space GP) are used

There is research in sensor calibration using GP in drifting environments. For example, Geng et al. developed a GP-based calibration model to deal with drift in chemical sensors, capturing environmental drift along with sensor response via GP modeling ([PMC][5]).

Also, a state-space GP model was used to estimate unknown drift functions in SDEs by converting GP to an approximated discrete filter-friendly form ([users.aalto.fi][4]).

---

## 3. Proposed stochastic drift model (your formulation)

Given these options, here’s how you can **formulate a drift model for your assignment**. You can pick one of these (or even compare a few) but you must state your assumptions clearly.

### 3.1. Choice & assumptions

Let me propose you adopt a **mixed AR(1) + random walk** drift model (or just AR(1) if you prefer simplicity). Assumptions:

* Drift is **additive** (i.e. measurement = true signal + drift + measurement noise).
* The dominant drift mechanisms (thermal, aging, calibration decay) manifest as a slowly varying bias.
* The drift evolves according to an AR(1) model:

  $d_{k+1} = \phi , d_k + w_k, \quad w_k \sim \mathcal{N}(0, \sigma_w^2)$

  where $(|\phi| \le 1).$
  
* If $(\phi = 1)$, this reduces to a random walk; if $(\phi < 1)$, drift tends to “relax” somewhat and not grow unbounded.
* The measurement noise is independent, zero-mean Gaussian:
  
  $v_k \sim \mathcal{N}(0, \sigma_v^2)$
  
* The underlying true signal (without drift) is $(x_k).$

Therefore, the **augmented model** is:

**State equation:**

$$
\begin{pmatrix} x_{k+1} \ d_{k+1} \end{pmatrix}
= \begin{pmatrix} 1 & 0 \ 0 & \phi \end{pmatrix}
\begin{pmatrix} x_k \ d_k \end{pmatrix}
* $w_k^{(x)} \ w_k
$$  

Here $(w_k^{(x)})$ is the process noise of the true signal (maybe zero or small) and (w_k) is drift process noise.

**Measurement equation:**

$y_k = x_k + d_k + v_k$

That is, observed reading = true signal + drift + measurement noise.

You can justify this model: it's linear, simple, implementable with Kalman filter, yet captures persistence (via (\phi)) and randomness (via (w_k)). Also, by choosing different (\phi), you can explore random-walk vs memory effects.

Optionally, you could replace the AR(1) drift with a **Gaussian process** prior:

$d(t) \sim \mathcal{GP}(0, K(t, t'))$

with a kernel like squared exponential:


$K(t, t') = \sigma_d^2 \exp\bigl(-\tfrac{(t - t')^2}{2 \ell^2}\bigr)$

and then do GP regression on residuals of sensor data to infer drift. Or combine it with state-space filtering (convert GP to state-space) ([users.aalto.fi][4]).

You could even compare performance between the AR(1) drift model vs GP drift model in your simulations / experiments.



[1]: https://www.vectornav.com/resources/inertial-navigation-primer/specifications--and--error-budgets/specs-imuspecs?utm_source=chatgpt.com "3.1 IMU Specifications"
[2]: https://en.wikipedia.org/wiki/Ornstein%E2%80%93Uhlenbeck_process?utm_source=chatgpt.com "Ornstein–Uhlenbeck process"
[3]: https://en.wikipedia.org/wiki/Gaussian_process?utm_source=chatgpt.com "Gaussian process"
[4]: https://users.aalto.fi/~ssarkka/pub/zhengzGP_SDE_camera_ready.pdf?utm_source=chatgpt.com "state-space gaussian process for drift estimation in stochastic"
[5]: https://pmc.ncbi.nlm.nih.gov/articles/PMC4764506/?utm_source=chatgpt.com "Gaussian process based modeling and experimental ..."
